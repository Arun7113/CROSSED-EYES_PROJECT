{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de885aa1-7594-4a96-a242-a6f4fab0ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting image from strabismus folder\n",
      "'.DS_Store' is not a directory, skipping.\n",
      "Getting image from normal folder\n",
      "num_classes 2\n",
      "Shape of image data (435, 224, 224, 3)\n",
      "number of samples 435\n",
      "target column before encoding ['strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17926338 (68.38 MB)\n",
      "Trainable params: 3211650 (12.25 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "10/10 [==============================] - 5s 485ms/step - loss: 3.1826 - accuracy: 0.5296 - val_loss: 1.3346 - val_accuracy: 0.5714\n",
      "Epoch 2/55\n",
      "10/10 [==============================] - 5s 463ms/step - loss: 3.3788 - accuracy: 0.6250 - val_loss: 0.8362 - val_accuracy: 0.7143\n",
      "Epoch 3/55\n",
      "10/10 [==============================] - 5s 459ms/step - loss: 3.5266 - accuracy: 0.6217 - val_loss: 1.3644 - val_accuracy: 0.7363\n",
      "Epoch 4/55\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 2.4498 - accuracy: 0.7599 - val_loss: 1.4041 - val_accuracy: 0.7253\n",
      "Epoch 5/55\n",
      "10/10 [==============================] - 5s 459ms/step - loss: 2.1103 - accuracy: 0.7697 - val_loss: 0.9338 - val_accuracy: 0.8352\n",
      "Epoch 6/55\n",
      "10/10 [==============================] - 5s 461ms/step - loss: 1.8489 - accuracy: 0.7829 - val_loss: 1.0198 - val_accuracy: 0.8571\n",
      "Epoch 7/55\n",
      "10/10 [==============================] - 5s 460ms/step - loss: 1.6339 - accuracy: 0.8191 - val_loss: 1.0144 - val_accuracy: 0.8022\n",
      "Epoch 8/55\n",
      "10/10 [==============================] - 5s 459ms/step - loss: 1.3887 - accuracy: 0.8257 - val_loss: 1.0740 - val_accuracy: 0.8571\n",
      "Epoch 9/55\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.8848 - accuracy: 0.9079 - val_loss: 0.7835 - val_accuracy: 0.8242\n",
      "Epoch 10/55\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.8571 - accuracy: 0.8849 - val_loss: 1.0223 - val_accuracy: 0.9011\n",
      "Epoch 11/55\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.6226 - accuracy: 0.9178 - val_loss: 0.8197 - val_accuracy: 0.8242\n",
      "Epoch 12/55\n",
      "10/10 [==============================] - 5s 460ms/step - loss: 0.5150 - accuracy: 0.9178 - val_loss: 1.2492 - val_accuracy: 0.8132\n",
      "Epoch 13/55\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.3742 - accuracy: 0.9408 - val_loss: 0.7231 - val_accuracy: 0.8571\n",
      "Epoch 14/55\n",
      "10/10 [==============================] - 5s 466ms/step - loss: 0.1890 - accuracy: 0.9638 - val_loss: 0.9160 - val_accuracy: 0.8681\n",
      "Epoch 15/55\n",
      "10/10 [==============================] - 5s 469ms/step - loss: 0.1023 - accuracy: 0.9803 - val_loss: 0.7050 - val_accuracy: 0.8571\n",
      "Epoch 16/55\n",
      "10/10 [==============================] - 5s 466ms/step - loss: 0.1308 - accuracy: 0.9836 - val_loss: 0.7307 - val_accuracy: 0.9231\n",
      "Epoch 17/55\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.1295 - accuracy: 0.9671 - val_loss: 0.6346 - val_accuracy: 0.9341\n",
      "Epoch 18/55\n",
      "10/10 [==============================] - 4s 457ms/step - loss: 0.0792 - accuracy: 0.9868 - val_loss: 0.7078 - val_accuracy: 0.8791\n",
      "Epoch 19/55\n",
      "10/10 [==============================] - 4s 457ms/step - loss: 0.0646 - accuracy: 0.9901 - val_loss: 0.8031 - val_accuracy: 0.8791\n",
      "Epoch 20/55\n",
      "10/10 [==============================] - 4s 458ms/step - loss: 0.0585 - accuracy: 0.9868 - val_loss: 0.7489 - val_accuracy: 0.8901\n",
      "Epoch 21/55\n",
      "10/10 [==============================] - 5s 461ms/step - loss: 0.0404 - accuracy: 0.9967 - val_loss: 0.8186 - val_accuracy: 0.8681\n",
      "Epoch 22/55\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 0.0378 - accuracy: 0.9901 - val_loss: 0.8025 - val_accuracy: 0.9121\n",
      "Epoch 23/55\n",
      "10/10 [==============================] - 5s 479ms/step - loss: 0.0248 - accuracy: 0.9967 - val_loss: 0.6760 - val_accuracy: 0.9011\n",
      "Epoch 24/55\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 0.0234 - accuracy: 0.9967 - val_loss: 0.8173 - val_accuracy: 0.9011\n",
      "Epoch 25/55\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.8062 - val_accuracy: 0.9121\n",
      "Epoch 26/55\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 0.0281 - accuracy: 0.9967 - val_loss: 0.6548 - val_accuracy: 0.9121\n",
      "Epoch 27/55\n",
      "10/10 [==============================] - 6s 641ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.9341\n",
      "Epoch 28/55\n",
      "10/10 [==============================] - 7s 724ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.8352\n",
      "Epoch 29/55\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.9011\n",
      "Epoch 30/55\n",
      "10/10 [==============================] - 9s 874ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.9011\n",
      "Epoch 31/55\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.8901\n",
      "Epoch 32/55\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.9231\n",
      "Epoch 33/55\n",
      "10/10 [==============================] - 9s 929ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.9341\n",
      "Epoch 34/55\n",
      "10/10 [==============================] - 8s 805ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.9121\n",
      "Epoch 35/55\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.9011\n",
      "Epoch 36/55\n",
      "10/10 [==============================] - 7s 712ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.9011\n",
      "Epoch 37/55\n",
      "10/10 [==============================] - 7s 698ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.9451\n",
      "Epoch 38/55\n",
      "10/10 [==============================] - 7s 724ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.9341\n",
      "Epoch 39/55\n",
      "10/10 [==============================] - 7s 726ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.9451\n",
      "Epoch 40/55\n",
      "10/10 [==============================] - 8s 803ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.9121\n",
      "Epoch 41/55\n",
      "10/10 [==============================] - 7s 699ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.9451\n",
      "Epoch 42/55\n",
      "10/10 [==============================] - 7s 694ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8420 - val_accuracy: 0.8791\n",
      "Epoch 43/55\n",
      "10/10 [==============================] - 7s 715ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.9011\n",
      "Epoch 44/55\n",
      "10/10 [==============================] - 7s 719ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.9560\n",
      "Epoch 45/55\n",
      "10/10 [==============================] - 7s 708ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.9121\n",
      "Epoch 46/55\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.9011\n",
      "Epoch 47/55\n",
      "10/10 [==============================] - 8s 784ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.9121\n",
      "Epoch 48/55\n",
      "10/10 [==============================] - 7s 759ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.9560\n",
      "Epoch 49/55\n",
      "10/10 [==============================] - 8s 781ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.9341\n",
      "Epoch 50/55\n",
      "10/10 [==============================] - 8s 817ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.9011\n",
      "Epoch 51/55\n",
      "10/10 [==============================] - 8s 868ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.9011\n",
      "Epoch 52/55\n",
      "10/10 [==============================] - 9s 879ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.9231\n",
      "Epoch 53/55\n",
      "10/10 [==============================] - 9s 920ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.9011\n",
      "Epoch 54/55\n",
      "10/10 [==============================] - 9s 903ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.9121\n",
      "Epoch 55/55\n",
      "10/10 [==============================] - 8s 835ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9560\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 0.6047 - accuracy: 0.9560\n",
      "Test Loss: 0.6046756505966187\n",
      "Test Accuracy: 0.9560439586639404\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import argmax\n",
    "\n",
    "PATH = \"augmented_image\"\n",
    "data_dir_list = os.listdir(PATH)\n",
    "data_dir_list\n",
    "\n",
    "img_rows=224\n",
    "img_cols=224\n",
    "num_channel=3\n",
    "\n",
    "num_epoch = 55\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "img_data_list = []\n",
    "classes_names_list = []\n",
    "target_column = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    if os.path.isdir(os.path.join(PATH, dataset)):  \n",
    "        classes_names_list.append(dataset)\n",
    "        print(\"Getting image from {} folder\".format(dataset))\n",
    "        img_list = os.listdir(os.path.join(PATH, dataset))\n",
    "        for img in img_list:\n",
    "            input_img = cv2.imread(os.path.join(PATH, dataset, img))\n",
    "            input_img_resize = cv2.resize(input_img, (img_rows, img_cols))\n",
    "            img_data_list.append(input_img_resize)\n",
    "            target_column.append(dataset)\n",
    "    else:\n",
    "        print(\"'{}' is not a directory, skipping.\".format(dataset))\n",
    "\n",
    "num_classes = len(classes_names_list)\n",
    "print(\"num_classes\",num_classes)\n",
    "img_data = np.array(img_data_list) \n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print(\"Shape of image data\",img_data.shape)\n",
    "num_of_samples = img_data.shape[0]\n",
    "input_shape = img_data[0].shape \n",
    "print(\"number of samples\",num_of_samples)\n",
    "print(\"target column before encoding\",target_column)\n",
    "\n",
    "Labelencoder = LabelEncoder()\n",
    "target_column = Labelencoder.fit_transform(target_column)\n",
    "np.unique(target_column)\n",
    "\n",
    "target_column\n",
    "\n",
    "target_column_hotcoded = to_categorical(target_column,num_classes)\n",
    "X,Y = shuffle(img_data,target_column_hotcoded,random_state=2)\n",
    "X_train,X_temp,y_train,y_temp = train_test_split(X,Y,test_size=0.3,random_state=2)\n",
    "X_test,X_val,y_test,y_val = train_test_split(X_temp,y_temp,test_size=0.3,random_state=2)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, num_channel))\n",
    "\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(vgg_model)\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test Accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "668282b1-8fb8-412c-8a2a-b12f3f80bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting image from strabismus folder\n",
      "'.DS_Store' is not a directory, skipping.\n",
      "Getting image from normal folder\n",
      "num_classes 2\n",
      "Shape of image data (435, 224, 224, 3)\n",
      "number of samples 435\n",
      "target column before encoding ['strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'strabismus', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17926338 (68.38 MB)\n",
      "Trainable params: 3211650 (12.25 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "5/5 [==============================] - 6s 1s/step - loss: 9.1347 - accuracy: 0.5329 - val_loss: 7.0171 - val_accuracy: 0.5495\n",
      "Epoch 2/55\n",
      "5/5 [==============================] - 5s 994ms/step - loss: 6.7064 - accuracy: 0.5888 - val_loss: 0.7729 - val_accuracy: 0.7253\n",
      "Epoch 3/55\n",
      "5/5 [==============================] - 5s 1s/step - loss: 5.1364 - accuracy: 0.5954 - val_loss: 4.1605 - val_accuracy: 0.5385\n",
      "Epoch 4/55\n",
      "5/5 [==============================] - 8s 2s/step - loss: 6.5334 - accuracy: 0.5855 - val_loss: 4.4334 - val_accuracy: 0.8022\n",
      "Epoch 5/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 6.5769 - accuracy: 0.5987 - val_loss: 2.1216 - val_accuracy: 0.7253\n",
      "Epoch 6/55\n",
      "5/5 [==============================] - 13s 3s/step - loss: 5.5959 - accuracy: 0.6382 - val_loss: 1.0878 - val_accuracy: 0.7143\n",
      "Epoch 7/55\n",
      "5/5 [==============================] - 13s 3s/step - loss: 5.5854 - accuracy: 0.6316 - val_loss: 0.7901 - val_accuracy: 0.7582\n",
      "Epoch 8/55\n",
      "5/5 [==============================] - 12s 3s/step - loss: 5.8677 - accuracy: 0.6480 - val_loss: 0.7663 - val_accuracy: 0.7473\n",
      "Epoch 9/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 5.0894 - accuracy: 0.6743 - val_loss: 1.2886 - val_accuracy: 0.7143\n",
      "Epoch 10/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 4.5689 - accuracy: 0.6941 - val_loss: 1.4281 - val_accuracy: 0.7253\n",
      "Epoch 11/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 5.0313 - accuracy: 0.6480 - val_loss: 1.2295 - val_accuracy: 0.7363\n",
      "Epoch 12/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 4.2838 - accuracy: 0.6974 - val_loss: 0.9321 - val_accuracy: 0.7912\n",
      "Epoch 13/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 4.0941 - accuracy: 0.7368 - val_loss: 0.7501 - val_accuracy: 0.8132\n",
      "Epoch 14/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 3.5901 - accuracy: 0.7730 - val_loss: 0.9943 - val_accuracy: 0.7473\n",
      "Epoch 15/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 3.4413 - accuracy: 0.7303 - val_loss: 1.0831 - val_accuracy: 0.7363\n",
      "Epoch 16/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 3.4044 - accuracy: 0.7664 - val_loss: 0.6341 - val_accuracy: 0.8352\n",
      "Epoch 17/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 2.5220 - accuracy: 0.8026 - val_loss: 0.8683 - val_accuracy: 0.8022\n",
      "Epoch 18/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 2.8811 - accuracy: 0.7730 - val_loss: 1.0149 - val_accuracy: 0.7912\n",
      "Epoch 19/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 2.2426 - accuracy: 0.8421 - val_loss: 0.6083 - val_accuracy: 0.8462\n",
      "Epoch 20/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 2.3651 - accuracy: 0.8059 - val_loss: 0.9714 - val_accuracy: 0.8022\n",
      "Epoch 21/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 2.1269 - accuracy: 0.8388 - val_loss: 0.7868 - val_accuracy: 0.8352\n",
      "Epoch 22/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.8874 - accuracy: 0.8684 - val_loss: 0.5162 - val_accuracy: 0.8681\n",
      "Epoch 23/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.8943 - accuracy: 0.8651 - val_loss: 0.6260 - val_accuracy: 0.8571\n",
      "Epoch 24/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 1.8035 - accuracy: 0.8816 - val_loss: 0.8074 - val_accuracy: 0.8352\n",
      "Epoch 25/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.4225 - accuracy: 0.9276 - val_loss: 0.5546 - val_accuracy: 0.8571\n",
      "Epoch 26/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.4219 - accuracy: 0.8980 - val_loss: 0.5466 - val_accuracy: 0.8571\n",
      "Epoch 27/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 1.4054 - accuracy: 0.8816 - val_loss: 0.7687 - val_accuracy: 0.8681\n",
      "Epoch 28/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.1406 - accuracy: 0.9013 - val_loss: 0.6122 - val_accuracy: 0.8571\n",
      "Epoch 29/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.8242 - accuracy: 0.9243 - val_loss: 0.6164 - val_accuracy: 0.8462\n",
      "Epoch 30/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.9616 - accuracy: 0.9145 - val_loss: 0.8573 - val_accuracy: 0.8571\n",
      "Epoch 31/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.7643 - accuracy: 0.9408 - val_loss: 0.5278 - val_accuracy: 0.8791\n",
      "Epoch 32/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7349 - accuracy: 0.9539 - val_loss: 0.5494 - val_accuracy: 0.8571\n",
      "Epoch 33/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.6395 - accuracy: 0.9539 - val_loss: 0.7284 - val_accuracy: 0.8681\n",
      "Epoch 34/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.7665 - accuracy: 0.9375 - val_loss: 0.5194 - val_accuracy: 0.8681\n",
      "Epoch 35/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.5464 - accuracy: 0.9539 - val_loss: 0.7397 - val_accuracy: 0.8681\n",
      "Epoch 36/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7422 - accuracy: 0.9572 - val_loss: 0.5480 - val_accuracy: 0.8681\n",
      "Epoch 37/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.4611 - accuracy: 0.9605 - val_loss: 0.5666 - val_accuracy: 0.8791\n",
      "Epoch 38/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.4351 - accuracy: 0.9737 - val_loss: 0.7685 - val_accuracy: 0.8791\n",
      "Epoch 39/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.4514 - accuracy: 0.9474 - val_loss: 0.6340 - val_accuracy: 0.8791\n",
      "Epoch 40/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.4558 - accuracy: 0.9704 - val_loss: 0.5256 - val_accuracy: 0.8791\n",
      "Epoch 41/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.3238 - accuracy: 0.9770 - val_loss: 0.6010 - val_accuracy: 0.8791\n",
      "Epoch 42/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2062 - accuracy: 0.9803 - val_loss: 0.5412 - val_accuracy: 0.8791\n",
      "Epoch 43/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2659 - accuracy: 0.9638 - val_loss: 0.6186 - val_accuracy: 0.8791\n",
      "Epoch 44/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2478 - accuracy: 0.9836 - val_loss: 0.7255 - val_accuracy: 0.8791\n",
      "Epoch 45/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1884 - accuracy: 0.9836 - val_loss: 0.6298 - val_accuracy: 0.8791\n",
      "Epoch 46/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2190 - accuracy: 0.9770 - val_loss: 0.4854 - val_accuracy: 0.9011\n",
      "Epoch 47/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1645 - accuracy: 0.9901 - val_loss: 0.6341 - val_accuracy: 0.8901\n",
      "Epoch 48/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1814 - accuracy: 0.9836 - val_loss: 0.8205 - val_accuracy: 0.8791\n",
      "Epoch 49/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1773 - accuracy: 0.9737 - val_loss: 0.4855 - val_accuracy: 0.8901\n",
      "Epoch 50/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1826 - accuracy: 0.9803 - val_loss: 0.4435 - val_accuracy: 0.9011\n",
      "Epoch 51/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1505 - accuracy: 0.9803 - val_loss: 0.5021 - val_accuracy: 0.8901\n",
      "Epoch 52/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1755 - accuracy: 0.9934 - val_loss: 0.6083 - val_accuracy: 0.8901\n",
      "Epoch 53/55\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.1247 - accuracy: 0.9934 - val_loss: 0.7376 - val_accuracy: 0.8901\n",
      "Epoch 54/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1019 - accuracy: 0.9934 - val_loss: 0.5763 - val_accuracy: 0.8901\n",
      "Epoch 55/55\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1371 - accuracy: 0.9868 - val_loss: 0.6106 - val_accuracy: 0.8901\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 0.6106 - accuracy: 0.8901\n",
      "Test Loss: 0.6105788350105286\n",
      "Test Accuracy: 0.8901098966598511\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x153685700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x153685700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 708ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "PATH = \"augmented_image\"\n",
    "data_dir_list = os.listdir(PATH)\n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "num_channel = 3\n",
    "num_epoch = 55\n",
    "batch_size = 64\n",
    "\n",
    "img_data_list = []\n",
    "classes_names_list = []\n",
    "target_column = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    if os.path.isdir(os.path.join(PATH, dataset)):  \n",
    "        classes_names_list.append(dataset)\n",
    "        print(\"Getting image from {} folder\".format(dataset))\n",
    "        img_list = os.listdir(os.path.join(PATH, dataset))\n",
    "        for img in img_list:\n",
    "            input_img = cv2.imread(os.path.join(PATH, dataset, img))\n",
    "            input_img_resize = cv2.resize(input_img, (img_rows, img_cols))\n",
    "            img_data_list.append(input_img_resize)\n",
    "            target_column.append(dataset)\n",
    "    else:\n",
    "        print(\"'{}' is not a directory, skipping.\".format(dataset))\n",
    "\n",
    "num_classes = len(classes_names_list)\n",
    "print(\"num_classes\", num_classes)\n",
    "img_data = np.array(img_data_list) \n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print(\"Shape of image data\", img_data.shape)\n",
    "num_of_samples = img_data.shape[0]\n",
    "input_shape = img_data[0].shape \n",
    "print(\"number of samples\", num_of_samples)\n",
    "print(\"target column before encoding\", target_column)\n",
    "\n",
    "Labelencoder = LabelEncoder()\n",
    "target_column = Labelencoder.fit_transform(target_column)\n",
    "np.unique(target_column)\n",
    "\n",
    "target_column_hotcoded = to_categorical(target_column, num_classes)\n",
    "X, Y = shuffle(img_data, target_column_hotcoded, random_state=2)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.3, random_state=2)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.3, random_state=2)\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, num_channel))\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test Accuracy:', score[1])\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes_names_list))\n",
    "plt.xticks(tick_marks, classes_names_list, rotation=45)\n",
    "plt.yticks(tick_marks, classes_names_list)\n",
    "for i in range(len(classes_names_list)):\n",
    "    for j in range(len(classes_names_list)):\n",
    "        plt.text(j, i, conf_matrix[i, j], horizontalalignment=\"center\", color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddba236-6f92-4084-a4fd-186bc5d499c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
