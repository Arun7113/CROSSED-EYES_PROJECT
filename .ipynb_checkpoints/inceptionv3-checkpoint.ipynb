{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9e6703-5d91-4418-8bab-684e813f1540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images from strabismus folder\n",
      "'.DS_Store' is not a directory, skipping.\n",
      "Getting images from normal folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6553728   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28356770 (108.17 MB)\n",
      "Trainable params: 6553986 (25.00 MB)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/45\n",
      "5/5 [==============================] - 5s 715ms/step - loss: 26.3950 - accuracy: 0.5888 - val_loss: 31.4637 - val_accuracy: 0.6044\n",
      "Epoch 2/45\n",
      "5/5 [==============================] - 2s 394ms/step - loss: 34.0883 - accuracy: 0.6316 - val_loss: 9.1471 - val_accuracy: 0.7473\n",
      "Epoch 3/45\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 35.9351 - accuracy: 0.6513 - val_loss: 9.4064 - val_accuracy: 0.7692\n",
      "Epoch 4/45\n",
      "5/5 [==============================] - 2s 369ms/step - loss: 33.8670 - accuracy: 0.6678 - val_loss: 8.9925 - val_accuracy: 0.7802\n",
      "Epoch 5/45\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 32.0198 - accuracy: 0.6908 - val_loss: 8.6683 - val_accuracy: 0.8022\n",
      "Epoch 6/45\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 33.8141 - accuracy: 0.6974 - val_loss: 7.2987 - val_accuracy: 0.8022\n",
      "Epoch 7/45\n",
      "5/5 [==============================] - 2s 389ms/step - loss: 29.8379 - accuracy: 0.7237 - val_loss: 6.5589 - val_accuracy: 0.8352\n",
      "Epoch 8/45\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 18.8613 - accuracy: 0.7730 - val_loss: 5.3325 - val_accuracy: 0.8462\n",
      "Epoch 9/45\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 20.6847 - accuracy: 0.7895 - val_loss: 5.5083 - val_accuracy: 0.8462\n",
      "Epoch 10/45\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 18.0569 - accuracy: 0.7829 - val_loss: 4.8941 - val_accuracy: 0.8791\n",
      "Epoch 11/45\n",
      "5/5 [==============================] - 2s 395ms/step - loss: 14.3062 - accuracy: 0.7632 - val_loss: 4.9990 - val_accuracy: 0.8462\n",
      "Epoch 12/45\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 14.2127 - accuracy: 0.7961 - val_loss: 5.1722 - val_accuracy: 0.8571\n",
      "Epoch 13/45\n",
      "5/5 [==============================] - 2s 401ms/step - loss: 13.8834 - accuracy: 0.8125 - val_loss: 5.5652 - val_accuracy: 0.8462\n",
      "Epoch 14/45\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 9.5507 - accuracy: 0.8289 - val_loss: 5.5414 - val_accuracy: 0.8462\n",
      "Epoch 15/45\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 8.5673 - accuracy: 0.8651 - val_loss: 8.3280 - val_accuracy: 0.8352\n",
      "Epoch 16/45\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 7.8009 - accuracy: 0.8816 - val_loss: 4.9407 - val_accuracy: 0.8462\n",
      "Epoch 17/45\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 6.1244 - accuracy: 0.8882 - val_loss: 6.1192 - val_accuracy: 0.8571\n",
      "Epoch 18/45\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 3.9086 - accuracy: 0.9211 - val_loss: 4.4533 - val_accuracy: 0.8462\n",
      "Epoch 19/45\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 3.7387 - accuracy: 0.9211 - val_loss: 6.6126 - val_accuracy: 0.8681\n",
      "Epoch 20/45\n",
      "5/5 [==============================] - 2s 376ms/step - loss: 2.5798 - accuracy: 0.9276 - val_loss: 4.3193 - val_accuracy: 0.8462\n",
      "Epoch 21/45\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 2.5956 - accuracy: 0.9441 - val_loss: 4.3917 - val_accuracy: 0.8791\n",
      "Epoch 22/45\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 2.4211 - accuracy: 0.9375 - val_loss: 4.3625 - val_accuracy: 0.8352\n",
      "Epoch 23/45\n",
      "5/5 [==============================] - 2s 394ms/step - loss: 1.3555 - accuracy: 0.9572 - val_loss: 4.3602 - val_accuracy: 0.8681\n",
      "Epoch 24/45\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 1.2517 - accuracy: 0.9507 - val_loss: 4.8411 - val_accuracy: 0.8901\n",
      "Epoch 25/45\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 1.3232 - accuracy: 0.9605 - val_loss: 4.5503 - val_accuracy: 0.8571\n",
      "Epoch 26/45\n",
      "5/5 [==============================] - 2s 398ms/step - loss: 0.9155 - accuracy: 0.9638 - val_loss: 4.5264 - val_accuracy: 0.8571\n",
      "Epoch 27/45\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.4896 - accuracy: 0.9704 - val_loss: 4.5369 - val_accuracy: 0.8791\n",
      "Epoch 28/45\n",
      "5/5 [==============================] - 2s 389ms/step - loss: 1.5852 - accuracy: 0.9638 - val_loss: 5.9778 - val_accuracy: 0.8791\n",
      "Epoch 29/45\n",
      "5/5 [==============================] - 2s 399ms/step - loss: 1.2992 - accuracy: 0.9605 - val_loss: 4.4909 - val_accuracy: 0.8681\n",
      "Epoch 30/45\n",
      "5/5 [==============================] - 2s 402ms/step - loss: 1.4249 - accuracy: 0.9671 - val_loss: 4.1011 - val_accuracy: 0.8791\n",
      "Epoch 31/45\n",
      "5/5 [==============================] - 2s 405ms/step - loss: 0.4614 - accuracy: 0.9638 - val_loss: 4.0973 - val_accuracy: 0.8901\n",
      "Epoch 32/45\n",
      "5/5 [==============================] - 2s 401ms/step - loss: 0.2736 - accuracy: 0.9901 - val_loss: 4.2769 - val_accuracy: 0.8791\n",
      "Epoch 33/45\n",
      "5/5 [==============================] - 2s 426ms/step - loss: 0.0558 - accuracy: 0.9836 - val_loss: 4.3607 - val_accuracy: 0.8791\n",
      "Epoch 34/45\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.0809 - accuracy: 0.9901 - val_loss: 4.3035 - val_accuracy: 0.8901\n",
      "Epoch 35/45\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.0942 - accuracy: 0.9836 - val_loss: 4.5264 - val_accuracy: 0.9121\n",
      "Epoch 36/45\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.5085 - accuracy: 0.9737 - val_loss: 4.5255 - val_accuracy: 0.8791\n",
      "Epoch 37/45\n",
      "5/5 [==============================] - 2s 391ms/step - loss: 0.1024 - accuracy: 0.9967 - val_loss: 5.2795 - val_accuracy: 0.8571\n",
      "Epoch 38/45\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.4425 - accuracy: 0.9836 - val_loss: 4.2636 - val_accuracy: 0.9121\n",
      "Epoch 39/45\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.6504 - accuracy: 0.9737 - val_loss: 7.6212 - val_accuracy: 0.8571\n",
      "Epoch 40/45\n",
      "5/5 [==============================] - 2s 394ms/step - loss: 0.3457 - accuracy: 0.9868 - val_loss: 4.7222 - val_accuracy: 0.8791\n",
      "Epoch 41/45\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 0.0339 - accuracy: 0.9934 - val_loss: 6.4361 - val_accuracy: 0.8571\n",
      "Epoch 42/45\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 0.3648 - accuracy: 0.9868 - val_loss: 4.8174 - val_accuracy: 0.8791\n",
      "Epoch 43/45\n",
      "5/5 [==============================] - 2s 433ms/step - loss: 1.1615e-04 - accuracy: 1.0000 - val_loss: 5.3013 - val_accuracy: 0.8791\n",
      "Epoch 44/45\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 0.2780 - accuracy: 0.9901 - val_loss: 6.1047 - val_accuracy: 0.8681\n",
      "Epoch 45/45\n",
      "5/5 [==============================] - 2s 462ms/step - loss: 0.2159 - accuracy: 0.9868 - val_loss: 4.2106 - val_accuracy: 0.9011\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 4.2106 - accuracy: 0.9011\n",
      "Test Loss: 4.210640907287598\n",
      "Test Accuracy: 0.901098906993866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "PATH = \"augmented_image\"\n",
    "\n",
    "\n",
    "data_dir_list = os.listdir(PATH)\n",
    "\n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "num_channel = 3\n",
    "\n",
    "\n",
    "num_epoch = 45\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "img_data_list = []\n",
    "classes_names_list = []\n",
    "target_column = []\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    if os.path.isdir(os.path.join(PATH, dataset)):\n",
    "        classes_names_list.append(dataset)\n",
    "        print(\"Getting images from {} folder\".format(dataset))\n",
    "        img_list = os.listdir(os.path.join(PATH, dataset))\n",
    "\n",
    "        for img in img_list:\n",
    "            input_img = cv2.imread(os.path.join(PATH, dataset, img))\n",
    "            input_img_resize = cv2.resize(input_img, (img_rows, img_cols))\n",
    "            img_data_list.append(input_img_resize)\n",
    "            target_column.append(dataset)\n",
    "    else:\n",
    "        print(\"'{}' is not a directory, skipping.\".format(dataset))\n",
    "\n",
    "\n",
    "Labelencoder = LabelEncoder()\n",
    "target_column = Labelencoder.fit_transform(target_column)\n",
    "num_classes = len(classes_names_list)\n",
    "\n",
    "\n",
    "img_data = np.array(img_data_list) \n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "\n",
    "\n",
    "X, Y = shuffle(img_data, target_column, random_state=2)\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.3, random_state=2)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.3, random_state=2)\n",
    "\n",
    "\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, num_channel))\n",
    "\n",
    "\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(inception_model)\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test Accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7eaf64-2533-4b50-be15-4050d375d4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
